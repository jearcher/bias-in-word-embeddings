{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "## This is how you link to a colab notebook\n",
    "\n",
    "\n",
    "<a href=\"<link to colab notebook\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bY4RMFQxrWyv",
    "outputId": "7926df4a-0561-4111-95a0-2a41ddc89e38"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations, filterfalse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Import local functions\n",
    "from WEAT_functions import *\n",
    "from Other_fxns import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word Lists used for Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptor Debias word lists\n",
    "sys.path.append('./ConceptorDebias')\n",
    "from lists.load_word_lists import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbRMmhwbGL98"
   },
   "source": [
    "## Load GloVe into Gensim Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embedding has been loaded.\n"
     ]
    }
   ],
   "source": [
    "glove = KeyedVectors.load_word2vec_format('data/embeddings/GloVe/GloVe_twitter_27B/glove.twitter.27B.100d.txt', \n",
    "                                          binary = False, \n",
    "                                          no_header = True)\n",
    "\n",
    "print(\"GloVe embedding has been loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing WEAT Stat (incomplete, just a test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upscdvtwFm0l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE\n",
      "WEAT d =  1.0688018\n",
      "WEAT p =  0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"List of association and target word pairs for the sample test (Instruments, Weapons) vs (Pleasant, Unpleasant)\"\"\"\n",
    "\n",
    "# Instruments\n",
    "X = [\"bagpipe\", \"cello\", \"guitar\", \"lute\", \"trombone\", \"banjo\", \"clarinet\", \"harmonica\", \"mandolin\", \"trumpet\", \"bassoon\", \"drum\", \"harp\", \"oboe\", \"tuba\", \"bell\", \"fiddle\", \"harpsichord\", \"piano\", \"viola\", \"bongo\",\n",
    "\"flute\", \"horn\", \"saxophone\", \"violin\"] \n",
    "# Weapons\n",
    "Y = [\"arrow\", \"club\", \"gun\", \"missile\", \"spear\", \"axe\", \"dagger\", \"harpoon\", \"pistol\", \"sword\", \"blade\", \"dynamite\", \"hatchet\", \"rifle\", \"tank\", \"bomb\", \"firearm\", \"knife\", \"shotgun\", \"teargas\", \"cannon\", \"grenade\",\n",
    "    \"mace\", \"slingshot\", \"whip\"] \n",
    "# Pleasant\n",
    "A = WEATLists.W_1_Pleasant\n",
    "# Unpleasant\n",
    "B = WEATLists.W_1_Unpleasant\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Compute the effect-size and P value\"\"\"\n",
    "print(\"GLOVE\")\n",
    "print('WEAT d = ', weat_effect_size(X, Y, A, B, glove))\n",
    "print('WEAT p = ', weat_p_value(X, Y, A, B, glove, 1000))\n",
    "\n",
    "#print(\"Word-Node2Vec\")\n",
    "#print('WEAT d = ', weat_effect_size(X, Y, A, B, wordNode2Vec))\n",
    "#print('WEAT p = ', weat_p_value(X, Y, A, B, wordNode2Vec, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE\n",
      "WEAT d =  0.1173317\n",
      "WEAT p =  0.403\n"
     ]
    }
   ],
   "source": [
    "X = WEATLists.W_8_Science\n",
    "Y = WEATLists.W_8_Arts\n",
    "A = WEATLists.W_8_Male_terms\n",
    "B = WEATLists.W_8_Female_terms\n",
    "\n",
    "print(\"GLOVE\")\n",
    "print('WEAT d = ', weat_effect_size(X, Y, A, B, glove))\n",
    "print('WEAT p = ', weat_p_value(X, Y, A, B, glove, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine lists for WEAT evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load list of pronouns representing the 'Pronoun' subspace for gender debiasing\"\"\"\n",
    "gender_list_pronouns = WEATLists.W_7_Male_terms + WEATLists.W_7_Female_terms + WEATLists.W_8_Male_terms + WEATLists.W_8_Female_terms\n",
    "gender_list_pronouns = list(set(gender_list_pronouns))\n",
    "\n",
    "\"\"\"Load an extended list of words representing the gender subspace for gender debiasing\"\"\"\n",
    "gender_list_extended = male_vino_extra + female_vino_extra + male_gnGlove + female_gnGlove\n",
    "gender_list_extended = list(set(gender_list_extended))\n",
    "\n",
    "\"\"\"Load list of proper nouns representing the 'Proper Noun' subspace for gender debiasing\"\"\"\n",
    "gender_list_propernouns = male_cmu + female_cmu\n",
    "gender_list_propernouns = list(set(gender_list_propernouns))\n",
    "\n",
    "\"\"\"Load list of all representing the gender subspace for gender debiasing\"\"\"\n",
    "gender_list_all = gender_list_pronouns + gender_list_extended + gender_list_propernouns\n",
    "gender_list_all = list(set(gender_list_all))\n",
    "\n",
    "\"\"\"Load list of common black and white names for racial debiasing\"\"\"\n",
    "race_list = WEATLists.W_3_Unused_full_list_European_American_names + WEATLists.W_3_European_American_names + WEATLists.W_3_Unused_full_list_African_American_names + WEATLists.W_3_African_American_names + WEATLists.W_4_Unused_full_list_European_American_names + WEATLists.W_4_European_American_names + WEATLists.W_4_Unused_full_list_African_American_names + WEATLists.W_4_African_American_names + WEATLists.W_5_Unused_full_list_European_American_names + WEATLists.W_5_European_American_names + WEATLists.W_5_Unused_full_list_African_American_names + WEATLists.W_5_African_American_names \n",
    "race_list = list(set(race_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resourceFile = ''\n",
    "wikiWordsPath = resourceFile + 'SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
    "\n",
    "\"\"\"Set the embedding to be used\"\"\"\n",
    "embd = 'glove'\n",
    "\n",
    "\"\"\"Set the subspace to be tested on\"\"\"\n",
    "subspace = 'gender_list_all' \n",
    "\n",
    "\"\"\"Load association and target word pairs\"\"\"\n",
    "X = WEATLists.W_8_Science\n",
    "Y = WEATLists.W_8_Arts\n",
    "A = WEATLists.W_8_Male_terms\n",
    "B = WEATLists.W_8_Female_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f6dc0c36f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_embd = eval(embd)\n",
    "all_words_index, all_words_mat = load_all_vectors(curr_embd, wikiWordsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Conceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "(100, 342)\n",
      "R calculated\n",
      "C calculated\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load the vectors for the words representing the subspace as a matrix and compute the respetive conceptor matrix\"\"\"\n",
    "if subspace != 'without_conceptor':\n",
    "  subspace_words_list = eval(subspace)\n",
    "  if subspace == 'gender_list_and':\n",
    "    if embd == 'elmo':\n",
    "      subspace_words_mat1 = load_subspace_vectors_contextual(all_words_mat, all_words_index, gender_list_pronouns)\n",
    "      cn1 = process_cn_matrix(np.array(subspace_words_mat1).T, alpha = 8)\n",
    "\n",
    "      subspace_words_mat2 = load_subspace_vectors_contextual(all_words_mat, all_words_index, gender_list_extended)\n",
    "      cn2 = process_cn_matrix(np.array(subspace_words_mat2).T, alpha = 3)\n",
    "\n",
    "      subspace_words_mat3 = load_subspace_vectors_contextual(all_words_mat, all_words_index, gender_list_propernouns)\n",
    "      cn3 = process_cn_matrix(np.array(subspace_words_mat3).T, alpha = 10)\n",
    "\n",
    "      cn = AND(cn1, AND(cn2, cn3))\n",
    "    elif embd == 'bert':\n",
    "      cn1 = load_bert_conceptor(all_dict, gender_list_pronouns)\n",
    "      \n",
    "      cn2 = load_bert_conceptor(all_dict, gender_list_extended)\n",
    "      \n",
    "      cn3 = load_bert_conceptor(all_dict, gender_list_propernouns)\n",
    "      \n",
    "      cn = AND(cn1, AND(cn2, cn3))\n",
    "    else:\n",
    "      subspace_words_mat1 = load_subspace_vectors(curr_embd, gender_list_pronouns)\n",
    "      cn1 = process_cn_matrix(np.array(subspace_words_mat1).T)\n",
    "\n",
    "      subspace_words_mat2 = load_subspace_vectors(curr_embd, gender_list_extended)\n",
    "      cn2 = process_cn_matrix(np.array(subspace_words_mat2).T)\n",
    "\n",
    "      subspace_words_mat3 = load_subspace_vectors(curr_embd, gender_list_propernouns)\n",
    "      cn3 = process_cn_matrix(np.array(subspace_words_mat3).T)\n",
    "\n",
    "      cn = AND(cn1, AND(cn2, cn3))\n",
    "  else: \n",
    "    if embd == 'elmo':\n",
    "      subspace_words_mat = load_subspace_vectors_contextual(all_words_mat, all_words_index, subspace_words_list)\n",
    "      cn = process_cn_matrix(np.array(subspace_words_mat).T, alpha = 6)\n",
    "    elif embd == 'bert':\n",
    "      cn = load_bert_conceptor(all_dict, subspace)\n",
    "    else:\n",
    "      subspace_words_mat = load_subspace_vectors(curr_embd, subspace_words_list)\n",
    "      cn = process_cn_matrix(np.array(subspace_words_mat).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Conceptored Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Conceptor all embeddings\"\"\"\n",
    "all_words_cn = apply_conceptor(np.array(all_words_mat).T, np.array(cn))\n",
    "\n",
    "\"\"\"Store all conceptored words in a dictonary\"\"\"\n",
    "all_words = {}\n",
    "for word, index in all_words_index.items():\n",
    "  if embd == 'elmo':\n",
    "    all_words[word] = np.mean([all_words_cn[i,:] for i in index], axis = 0)\n",
    "  else:\n",
    "    all_words[word] = all_words_cn[index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT on original GloVe =  0.1173317\n",
      "WEAT on Debias GloVe =  -0.14090246335130263\n"
     ]
    }
   ],
   "source": [
    "# Before Debias \n",
    "pre = weat_effect_size(X, Y, A, B, glove)\n",
    "\n",
    "d = weat_effect_size(X, Y, A, B, all_words)\n",
    "# p = weat_p_value(X, Y, A, B, all_words, 1000)\n",
    "\n",
    "print('WEAT on original GloVe = ', pre)\n",
    "print('WEAT on Debias GloVe = ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "WEAT (Final).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
