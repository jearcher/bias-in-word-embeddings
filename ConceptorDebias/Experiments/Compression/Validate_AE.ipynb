{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.init()\n",
    "device = torch.device('cuda:1')\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__() \n",
    "        \n",
    "        #encode\n",
    "        self.e1 = nn.Linear(9216,4608)\n",
    "        self.e2 = nn.Linear(4608,1024)\n",
    "        \n",
    "        #decode\n",
    "        self.d1 = nn.Linear(1024,4608)\n",
    "        self.d2 = nn.Linear(4608,9216)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode = self.e2(F.relu(self.e1(x)))\n",
    "        \n",
    "        return self.d2(F.relu(self.d1(encode)))\n",
    "\n",
    "# class AutoEncoder(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(AutoEncoder, self).__init__() \n",
    "        \n",
    "#         #encode\n",
    "#         self.e1 = nn.Linear(9216,6000)\n",
    "#         self.e2 = nn.Linear(6000,4000)\n",
    "# #         self.e3 = nn.Linear(4000,2000)\n",
    "# #         self.e4 = nn.Linear(2000,1000)\n",
    "        \n",
    "#         #decode\n",
    "# #         self.d1 = nn.Linear(1000,2000)\n",
    "# #         self.d3 = nn.Linear(2000,4000)\n",
    "#         self.d1 = nn.Linear(4000,6000)\n",
    "#         self.d2 = nn.Linear(6000,9216)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         encode = self.e2(F.relu(self.e1(x)))\n",
    "#         return self.d2(F.relu(self.d1(encode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/ssd2/chetanp'\n",
    "batch_size = int((2 ** 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CosineSimilarity()\n",
    "\n",
    "loss_function = lambda x,y: (1-criterion(x,y)).mean()\n",
    "\n",
    "# loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder(\n",
       "    (e1): Linear(in_features=9216, out_features=4608, bias=True)\n",
       "    (e2): Linear(in_features=4608, out_features=1024, bias=True)\n",
       "    (d1): Linear(in_features=1024, out_features=4608, bias=True)\n",
       "    (d2): Linear(in_features=4608, out_features=9216, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder(),device_ids =[1,2]).to(device)\n",
    "path = os.path.join(base_path,'brown_e_base_compressor_superfine.pth')\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(2):\n",
    "    path = os.path.join(base_path,'brown_e_base'+str(i+4)+'.pt')\n",
    "    data = torch.load(path)\n",
    "    dataset.append(TensorDataset(data))\n",
    "dataset = ConcatDataset(dataset)\n",
    "data_loader = DataLoader(dataset,batch_size = batch_size,num_workers = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:16,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Loss:  0.04370893998181119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "count = 0\n",
    "    \n",
    "for i,data in tqdm(enumerate(data_loader)):\n",
    "    ## Get Data\n",
    "    sample = data[0].to(device)\n",
    "        \n",
    "    ## Pass forward\n",
    "    output = model(sample)\n",
    "    loss = loss_function(output,sample)\n",
    "      \n",
    "    ## Update Running Loss\n",
    "    running_loss += float(loss)\n",
    "    count += 1\n",
    "    \n",
    "#     if i == 0:\n",
    "#         diff = sample-output\n",
    "#         value = torch.sum(diff.pow(2), dim = 1).mean()\n",
    "#         print(value)\n",
    "print('Test Set Loss: ', str(running_loss/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(6):\n",
    "    path = os.path.join(base_path,'brown_e_base'+str(i)+'.pt')\n",
    "    data = torch.load(path)\n",
    "    dataset.append(TensorDataset(data))\n",
    "dataset = ConcatDataset(dataset)\n",
    "data_loader = DataLoader(dataset,batch_size = batch_size,num_workers = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:59<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Loss:  0.03977823509296901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "count = 0\n",
    "    \n",
    "for data in tqdm(data_loader):\n",
    "    ## Get Data\n",
    "    sample = data[0].to(device)\n",
    "        \n",
    "    ## Pass forward\n",
    "    output = model(sample)\n",
    "    loss = loss_function(output,sample)\n",
    "      \n",
    "    ## Update Running Loss\n",
    "    running_loss += float(loss)\n",
    "    count += 1\n",
    "        \n",
    "print('Overall Loss: ', str(running_loss/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(4):\n",
    "    path = os.path.join(base_path,'brown_e_base'+str(i)+'.pt')\n",
    "    data = torch.load(path)\n",
    "    dataset.append(TensorDataset(data))\n",
    "dataset = ConcatDataset(dataset)\n",
    "data_loader = DataLoader(dataset,batch_size = batch_size,num_workers = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:46<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.03854962655089118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "count = 0\n",
    "    \n",
    "for data in tqdm(data_loader):\n",
    "    ## Get Data\n",
    "    sample = data[0].to(device)\n",
    "        \n",
    "    ## Pass forward\n",
    "    output = model(sample)\n",
    "    loss = loss_function(output,sample)\n",
    "      \n",
    "    ## Update Running Loss\n",
    "    running_loss += float(loss)\n",
    "    count += 1\n",
    "        \n",
    "print('Training Loss: ', str(running_loss/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
